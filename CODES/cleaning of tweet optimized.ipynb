{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20b557f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c57324",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcee3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33250909",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e257f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938d6955",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95f8cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd174e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contractions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abeff14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5fd548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170429e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d046962c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a44ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6466f321",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75690fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from num2words import num2words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e84c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36acd12b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('final.csv').iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3448e88",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweets['Tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d134627",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet[17]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a52f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2323cbac",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02f9e0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "punct_words = list(string.punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953fe619",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = stop_words + punct_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc9d79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop = list(set(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f213bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_easy_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb3b1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad27ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "spell = SpellChecker()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbaf9cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitise = lambda x: re.sub('-|\\s+', '', num2words(x.group()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32fea75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(text):\n",
    "    unurl = re.sub('http[s]?://\\S+', '', str(text).strip().lower())\n",
    "    for i in unurl.split():\n",
    "        if i[0] in ['#', '@']:\n",
    "            unurl = unurl.replace(i, ' ')\n",
    "    unspaced = ' '.join(unurl.split()).strip()\n",
    "    expanded = contractions.fix(unspaced)\n",
    "    digit_to_word = re.sub(r'\\d+', digitise, expanded)\n",
    "    clean_words = []\n",
    "    for word in word_tokenize(digit_to_word):\n",
    "        if word not in stop:\n",
    "            pos = pos_tag([word])\n",
    "            clean_word = lemmatizer.lemmatize(word, get_easy_pos(pos[0][1]))\n",
    "            clean_words.append(clean_word)\n",
    "    clean_words = ' '.join(clean_words)\n",
    "    correct_word = checker.correct(clean_words)\n",
    "    return correct_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3653e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet0 = tweet[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640dae7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "new_tweet0 = tweet0.apply(f1)\n",
    "print('time_taken : ', time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1798391f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweet0), len(new_tweet0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47600239",
   "metadata": {},
   "outputs": [],
   "source": [
    "st = time.time()\n",
    "new_tweet = tweet.apply(f1)\n",
    "print('time_taken : ', time.time() - st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac65a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('time for preprocessing in min: ', 3032 / 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db238ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['Tweets'] = new_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "720034f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fc0bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.iloc[78, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea15612",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_1(lines):\n",
    "    n = len(lines)\n",
    "    lines_thresh_bool = np.ones((n * n,), dtype=np.bool)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            line1 = lines[i]\n",
    "            n1 = len(line1)\n",
    "            line2 = lines[j]\n",
    "            n2 = len(line2)\n",
    "            n_max = max(n1, n2)\n",
    "            n_min = min(n1, n2)\n",
    "            count_true = 0\n",
    "            for k in range(n_min):\n",
    "                if line1[k] == line2[k]:\n",
    "                    count_true += 1\n",
    "            thresh_true = round(count_true / n_max, 2)\n",
    "            thresh_false = 1 - thresh_true\n",
    "            if (thresh_true <= 0.25) or (0.75 <= thresh_false):\n",
    "                lines_thresh_bool[(n * i) + j] = False\n",
    "                lines_thresh_bool[i + (n * j)] = False\n",
    "    return lines_thresh_bool.reshape(n, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827d21b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_2(lines, lines_thresh_bool):\n",
    "    tweet_lines_thresh_bool = pd.DataFrame(lines_thresh_bool.T)\n",
    "    tweet_lines_thresh_bool.insert(0, 'tweet', pd.DataFrame(np.array(lines)))\n",
    "    l = set()\n",
    "    for i in range(len(lines)):\n",
    "        d = tweet_lines_thresh_bool[tweet_lines_thresh_bool[i] == True]['tweet'].to_dict()\n",
    "        for k in d:\n",
    "            d[k] = len(d[k])\n",
    "        d = dict(sorted(d.items(), key=lambda x: x[1], reverse=True))\n",
    "        l.add(list(d.keys())[0])\n",
    "    l = list(l)\n",
    "    refined_tweets = tweet_lines_thresh_bool.loc[l, 'tweet'].to_list()\n",
    "    return refined_tweets, l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3547e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_tweets = []\n",
    "for t in new_tweet:\n",
    "    a_tweets.append(word_tokenize(str(t).strip()))\n",
    "len(a_tweets)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
