{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36b8e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import pos_tag\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0904b385",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv('final.csv').iloc[:,1:]\n",
    "tweet = tweets['Tweets']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words.remove('not')\n",
    "punct_words = list(string.punctuation)\n",
    "stop = stop_words + punct_words\n",
    "stop = list(set(stop))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d228adb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6746f845",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_easy_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8dbc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(f'[{string.punctuation}]', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [word for word in words if word not in stop]\n",
    "    words = [lemmatizer.lemmatize(word, get_easy_pos(pos_tag([word])[0][1])) for word in words]\n",
    "    return ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81654981",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet0 = tweet[:50]\n",
    "processed_tweet0 = tweet0.apply(process_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a38d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def phase_1(lines):\n",
    "    n = len(lines)\n",
    "    lines_thresh_bool = np.ones((n * n,), dtype=np.bool)\n",
    "    for i in range(n):\n",
    "        for j in range(i + 1, n):\n",
    "            line1 = lines[i]\n",
    "            n1 = len(line1)\n",
    "            line2 = lines[j]\n",
    "            n2 = len(line2)\n",
    "            n_max = max(n1, n2)\n",
    "            n_min = min(n1, n2)\n",
    "            count_true = 0\n",
    "            for k in range(n_min):\n",
    "                if line1[k] == line2[k]:\n",
    "                    count_true += 1\n",
    "           thresh_true = round(count_true / n_max, 2)\n",
    "            thresh_false = 1 - thresh_true\n",
    "            if (thresh_true <= 0.25) or (0.75 <= thresh_false):\n",
    "                lines_thresh_bool[(n * i) + j] = False\n",
    "                lines_thresh_bool[i + (n * j)] = False\n",
    "    return lines_thresh_bool.reshape(n, n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d6e35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_lines = ['This is a test', 'Another test line', 'Something different']\n",
    "result = phase_1(sample_lines)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
